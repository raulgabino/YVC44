import { type NextRequest, NextResponse } from "next/server"
import { openai, MODELS, MODEL_CONFIGS } from "@/lib/config"

function buildMainPrompt(query: string): string {
  return `Eres un experto en geograf√≠a mexicana y lenguaje coloquial. Analiza esta b√∫squeda: "${query}"

EXTRAE DOS DATOS EXACTOS:
1. **VIBE**: Una opci√≥n de la lista de VIBES DISPONIBLES
2. **CIUDAD**: El nombre completo y correcto de la ciudad mexicana mencionada

VIBES DISPONIBLES (elige SOLO UNA):
- Traka: fiesta, revent√≥n, antro
- Bellakeo: ligar, perrear, sensual  
- Tranqui: relajado, chill, calmo
- God√≠nez: trabajo, oficina, profesional
- Dominguero: familia, casual, paseo
- Chambeador: trabajar, estudiar, wifi
- T√≥xico: intenso, dram√°tico, catarsis
- Dateo: cita, rom√°ntico, pareja
- Crudo: resaca, hangover, curar
- Barb√≥n: fresa, elegante, sofisticado

DETECCI√ìN DE CIUDADES - EJEMPLOS CR√çTICOS:
"ciudad juarez" ‚Üí "Ciudad Ju√°rez"
"nuevo laredo" ‚Üí "Nuevo Laredo"
"tijuana" ‚Üí "Tijuana"
"le√≥n" ‚Üí "Le√≥n"
"puebla" ‚Üí "Puebla"
"m√©rida" ‚Üí "M√©rida"
"canc√∫n" ‚Üí "Canc√∫n"
"gdl" o "guadalajara" ‚Üí "Guadalajara"
"monterrey" o "mty" ‚Üí "Monterrey"
"cdmx" o "df" o "la roma" o "polanco" o "condesa" ‚Üí "CDMX"
"ciudad victoria" o "victoria" ‚Üí "Ciudad Victoria"
"san miguel" o "san miguel de allende" ‚Üí "San Miguel de Allende"

REGLA CR√çTICA: Si NO se menciona ciudad espec√≠fica, SOLO entonces usa "CDMX" por defecto.

EJEMPLOS DE DETECCI√ìN:
"un lugar tranqui en ciudad juarez" ‚Üí {"vibe": "Tranqui", "city": "Ciudad Ju√°rez"}
"algo para bellakear en tijuana" ‚Üí {"vibe": "Bellakeo", "city": "Tijuana"}  
"caf√© para chambear en le√≥n" ‚Üí {"vibe": "Chambeador", "city": "Le√≥n"}
"bar barb√≥n en m√©rida" ‚Üí {"vibe": "Barb√≥n", "city": "M√©rida"}
"lugar dominguero en ciudad victoria" ‚Üí {"vibe": "Dominguero", "city": "Ciudad Victoria"}
"restaurante para dateo en san miguel" ‚Üí {"vibe": "Dateo", "city": "San Miguel de Allende"}

RESPONDE SOLO CON JSON:
{"vibe": "nombre_exacto", "city": "nombre_ciudad_completo"}`
}

export async function POST(request: NextRequest) {
  try {
    const { query } = await request.json()

    if (!query || typeof query !== "string" || query.trim().length === 0) {
      return NextResponse.json({ error: "Query is required and must be a non-empty string" }, { status: 400 })
    }

    console.log("üîç Analyzing query:", query)

    if (!openai) {
      console.warn("‚ö†Ô∏è OpenAI not configured, using manual analysis")
      const manualResult = analyzeQueryManually(query.trim())
      return NextResponse.json({
        ...manualResult,
        model_used: "manual",
        confidence: "low",
      })
    }

    const mainPrompt = buildMainPrompt(query.trim())

    // Try primary model first (o3-mini)
    try {
      console.log("ü§ñ Calling OpenAI with primary model...")
      const controller = new AbortController()
      const timeoutId = setTimeout(() => controller.abort(), 10000)

      const completion = await Promise.race([
        openai.chat.completions.create(
          {
            model: MODELS.OPENAI.PRIMARY,
            messages: [
              {
                role: "system",
                content:
                  "Eres un experto en an√°lisis de lenguaje coloquial mexicano. Responde √∫nicamente con JSON v√°lido, sin texto adicional.",
              },
              {
                role: "user",
                content: mainPrompt,
              },
            ],
            ...MODEL_CONFIGS[MODELS.OPENAI.PRIMARY],
          },
          { signal: controller.signal },
        ),
        new Promise<never>((_, reject) => setTimeout(() => reject(new Error("Timeout")), 10000)),
      ])

      clearTimeout(timeoutId)

      const response = completion.choices[0].message.content?.trim()
      console.log("üì• OpenAI response:", response)

      if (response) {
        try {
          const jsonMatch = response.match(/\{[^}]*\}/)
          const jsonStr = jsonMatch ? jsonMatch[0] : response
          const parsed = JSON.parse(jsonStr)

          const validVibes = [
            "Traka",
            "Bellakeo",
            "Tranqui",
            "God√≠nez",
            "Dominguero",
            "Chambeador",
            "T√≥xico",
            "Dateo",
            "Crudo",
            "Barb√≥n",
          ]

          if (parsed.vibe && parsed.city && validVibes.includes(parsed.vibe)) {
            console.log("‚úÖ Valid detection:", parsed)
            return NextResponse.json({
              ...parsed,
              model_used: MODELS.OPENAI.PRIMARY,
              confidence: "high",
            })
          }
        } catch (parseError) {
          console.error("‚ùå JSON parsing failed:", parseError)
        }
      }
    } catch (openaiError) {
      console.error("‚ùå Primary model failed:", openaiError)
    }

    // Try fallback model (gpt-4o-mini)
    try {
      console.log("üîÑ Trying fallback model...")
      const controller = new AbortController()
      const timeoutId = setTimeout(() => controller.abort(), 8000)

      const fallbackCompletion = await Promise.race([
        openai.chat.completions.create(
          {
            model: MODELS.OPENAI.FALLBACK,
            messages: [
              {
                role: "system",
                content:
                  "Eres un experto en an√°lisis de lenguaje coloquial mexicano. Responde √∫nicamente con JSON v√°lido, sin texto adicional.",
              },
              {
                role: "user",
                content: mainPrompt,
              },
            ],
            ...MODEL_CONFIGS[MODELS.OPENAI.FALLBACK],
          },
          { signal: controller.signal },
        ),
        new Promise<never>((_, reject) => setTimeout(() => reject(new Error("Timeout")), 8000)),
      ])

      clearTimeout(timeoutId)

      const fallbackResponse = fallbackCompletion.choices[0].message.content?.trim()

      if (fallbackResponse) {
        try {
          const jsonMatch = fallbackResponse.match(/\{[^}]*\}/)
          const jsonStr = jsonMatch ? jsonMatch[0] : fallbackResponse
          const parsed = JSON.parse(jsonStr)

          if (parsed.vibe && parsed.city) {
            return NextResponse.json({
              ...parsed,
              model_used: MODELS.OPENAI.FALLBACK,
              confidence: "medium",
            })
          }
        } catch (parseError) {
          console.warn("‚ö†Ô∏è Fallback JSON parsing failed:", parseError)
        }
      }
    } catch (fallbackError) {
      console.error("‚ùå Fallback model failed:", fallbackError)
    }

    // Final fallback: manual analysis
    console.log("üîß Using manual analysis")
    const manualResult = analyzeQueryManually(query.trim())

    return NextResponse.json({
      ...manualResult,
      model_used: "manual",
      confidence: "low",
    })
  } catch (error) {
    console.error("üí• Error in vibe detection:", error)
    return NextResponse.json({ error: "Error processing vibe detection" }, { status: 500 })
  }
}

function analyzeQueryManually(query: string): { vibe: string; city: string } {
  const lowerQuery = query.toLowerCase()

  // Enhanced city detection with more Mexican cities
  let city = "CDMX" // Default fallback

  const cityMappings = [
    { patterns: ["ciudad juarez", "juarez"], city: "Ciudad Ju√°rez" },
    { patterns: ["nuevo laredo", "laredo"], city: "Nuevo Laredo" },
    { patterns: ["tijuana", "tj"], city: "Tijuana" },
    { patterns: ["le√≥n", "leon"], city: "Le√≥n" },
    { patterns: ["puebla"], city: "Puebla" },
    { patterns: ["m√©rida", "merida"], city: "M√©rida" },
    { patterns: ["canc√∫n", "cancun"], city: "Canc√∫n" },
    { patterns: ["gdl", "guadalajara", "zapopan"], city: "Guadalajara" },
    { patterns: ["mty", "monterrey", "san pedro"], city: "Monterrey" },
    { patterns: ["ciudad victoria", "victoria"], city: "Ciudad Victoria" },
    { patterns: ["san miguel", "san miguel de allende", "allende"], city: "San Miguel de Allende" },
    { patterns: ["polanco", "roma", "condesa", "santa fe", "cdmx", "df"], city: "CDMX" },
  ]

  for (const { patterns, city: mappedCity } of cityMappings) {
    if (patterns.some((pattern) => lowerQuery.includes(pattern))) {
      city = mappedCity
      break
    }
  }

  // Enhanced vibe detection with priority order
  const vibePatterns = [
    { vibe: "Bellakeo", keywords: ["bellak", "bellaque", "ligar", "seducir", "perrear"] },
    { vibe: "Barb√≥n", keywords: ["barb√≥n", "fresa", "elegante", "sofisticad", "exclusivo", "clase alta"] },
    { vibe: "Chambeador", keywords: ["chambear", "trabajar", "estudiar", "wifi", "productiv"] },
    { vibe: "Crudo", keywords: ["crudo", "resaca", "desayun", "hangover", "recovery"] },
    { vibe: "Traka", keywords: ["traka", "fiesta", "revent√≥n", "parrandear", "party"] },
    { vibe: "Dateo", keywords: ["rom√°ntico", "cita", "dateo", "√≠ntimo", "pareja"] },
    { vibe: "God√≠nez", keywords: ["god√≠n", "trabajo", "oficina", "ejecutivo", "profesional"] },
    { vibe: "Dominguero", keywords: ["dominguero", "familia", "domingo", "casual", "familiar"] },
    { vibe: "T√≥xico", keywords: ["t√≥xico", "dram√°tic", "intenso", "emocional", "cat√°rtico"] },
    { vibe: "Tranqui", keywords: ["tranqui", "chill", "relajad", "zen", "calma"] },
  ]

  for (const { vibe, keywords } of vibePatterns) {
    if (keywords.some((keyword) => lowerQuery.includes(keyword))) {
      return { vibe, city }
    }
  }

  return { vibe: "Tranqui", city }
}
